{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## [Settings] 라이브러리 임포트 및 다운로드"
      ],
      "metadata": {
        "id": "rSTTfRP8ZGGn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4zmlE9ksZLhp",
        "outputId": "6da7670c-2680-427e-817d-600e6ad90b66"
      },
      "execution_count": 194,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.35.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.17.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.15,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.14.1)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow_addons"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lpWgOjlUZM4d",
        "outputId": "af4fe849-345a-4a4d-a3af-1e2f03e0b2de"
      },
      "execution_count": 195,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow_addons in /usr/local/lib/python3.10/dist-packages (0.22.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow_addons) (23.2)\n",
            "Requirement already satisfied: typeguard<3.0.0,>=2.7 in /usr/local/lib/python3.10/dist-packages (from tensorflow_addons) (2.13.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "from tqdm import tqdm\n",
        "import urllib.request\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow_addons as tfa\n",
        "import tensorflow as tf\n",
        "import torch\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from transformers import BertTokenizer, TFBertForSequenceClassification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, \\\n",
        "                            roc_auc_score, confusion_matrix, classification_report, \\\n",
        "                            matthews_corrcoef, cohen_kappa_score, log_loss"
      ],
      "metadata": {
        "id": "-xrPn8tJZJak"
      },
      "execution_count": 196,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## [Settings] 구글 드라이브 연동"
      ],
      "metadata": {
        "id": "tPfvP8bXYhmq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 197,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0loW1LlYYdaF",
        "outputId": "8fba6bb4-2ec9-420c-9cd6-05bb95bdc01b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.listdir('drive/MyDrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 184
        },
        "id": "lFDjNn_VYkj5",
        "outputId": "b0e13b3e-28d8-401d-dda7-5d1edc0db931"
      },
      "execution_count": 198,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-198-bef873e82e32>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'drive/MyDrive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'drive/MyDrive'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.chdir('drive/MyDrive/주분2주차')"
      ],
      "metadata": {
        "id": "f8ASjaj9YytG"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## [Settings] GPU 설정"
      ],
      "metadata": {
        "id": "jnsUwxL4Y5TQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_devices = torch.cuda.device_count()\n",
        "print(n_devices)\n",
        "\n",
        "for i in range(n_devices):\n",
        "    print(torch.cuda.get_device_name(i))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MXN7LznpY8Lj",
        "outputId": "362424fd-c700-4279-b5fe-ad9f1ea00ce5"
      },
      "execution_count": 199,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n",
            "Tesla V100-SXM2-16GB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 0. 데이터 로드"
      ],
      "metadata": {
        "id": "d2moJFVRam4x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = pd.read_csv(\"최종데이터셋.csv\")\n",
        "len(dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ulY-sLrTao3C",
        "outputId": "355562d1-26bb-403d-e0e0-575534a1b93d"
      },
      "execution_count": 200,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2522"
            ]
          },
          "metadata": {},
          "execution_count": 200
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. 언어모델 및 tokenizer 불러오기"
      ],
      "metadata": {
        "id": "DAfCXx3iY0Wx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_NAME = \"klue/bert-base\"\n",
        "model = TFBertForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=3, from_pt=True)\n",
        "tokenizer = BertTokenizer.from_pretrained(MODEL_NAME)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8UNXs-XxY2M2",
        "outputId": "32cd274e-bde5-4188-af95-3340bcdb6575"
      },
      "execution_count": 201,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertForSequenceClassification: ['bert.embeddings.position_ids']\n",
            "- This IS expected if you are initializing TFBertForSequenceClassification from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertForSequenceClassification from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. 데이터 분리"
      ],
      "metadata": {
        "id": "3nFlgabtax4J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 입출력 데이터 분리\n",
        "\n",
        "X_data = dataset['comments']\n",
        "y_data = dataset['label']\n",
        "\n",
        "TEST_SIZE = 0.2 # Train: Test = 9 : 1 분리\n",
        "RANDOM_STATE = 42\n",
        "# strtify = True 일 경우, 데이터 분리 이전의 라벨별 분포 고려\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_data, y_data,\n",
        "                                                    test_size = TEST_SIZE,\n",
        "                                                    random_state = RANDOM_STATE,\n",
        "                                                    stratify = y_data)"
      ],
      "metadata": {
        "id": "SmbZaKXbazMc"
      },
      "execution_count": 202,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"훈련 입력 데이터 개수: {len(X_train)}\")\n",
        "print(f\"테스트 입력 데이터 개수: {len(X_test)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y7UVveX2a48M",
        "outputId": "26976a83-d246-4c50-acc2-45a9c21bbe1a"
      },
      "execution_count": 203,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "훈련 입력 데이터 개수: 2017\n",
            "테스트 입력 데이터 개수: 505\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 훈련 데이터 라벨별 비율\n",
        "y_train.value_counts(normalize = True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jjC8ojwTa6s3",
        "outputId": "1ddbbbe8-240d-40cf-b54d-57384f77e0c1"
      },
      "execution_count": 204,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    0.500248\n",
              "0    0.499752\n",
              "Name: label, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 204
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 테스트 데이터 라벨별 비율\n",
        "y_test.value_counts(normalize = True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xsB2XcT0a8V1",
        "outputId": "c7814ed1-318d-4df0-ff00-ad874b836cb0"
      },
      "execution_count": 205,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    0.50099\n",
              "1    0.49901\n",
              "Name: label, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 205
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. BERT 입력용 데이터 포맷으로 변경"
      ],
      "metadata": {
        "id": "poEGGaTmbC5m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 입력 데이터(문장) 길이 제한\n",
        "MAX_SEQ_LEN = 128"
      ],
      "metadata": {
        "id": "3I3Hr9qnbFO7"
      },
      "execution_count": 206,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_data(X_data, y_data):\n",
        "    # BERT 입력으로 들어가는 token, mask, segment, target 저장용 리스트\n",
        "    tokens, masks, segments, targets = [], [], [], []\n",
        "\n",
        "    for X, y in tqdm(zip(X_data, y_data)):\n",
        "        # token: 입력 문장 토큰화\n",
        "        token = tokenizer.encode(X, truncation = True, padding = 'max_length', max_length = MAX_SEQ_LEN)\n",
        "\n",
        "        # Mask: 토큰화한 문장 내 패딩이 아닌 경우 1, 패딩인 경우 0으로 초기화\n",
        "        num_zeros = token.count(0)\n",
        "        mask = [1] * (MAX_SEQ_LEN - num_zeros) + [0] * num_zeros\n",
        "\n",
        "        # segment: 문장 전후관계 구분: 오직 한 문장이므로 모두 0으로 초기화\n",
        "        segment = [0]*MAX_SEQ_LEN\n",
        "\n",
        "        tokens.append(token)\n",
        "        masks.append(mask)\n",
        "        segments.append(segment)\n",
        "        targets.append(y)\n",
        "\n",
        "    # numpy array로 저장\n",
        "    tokens = np.array(tokens)\n",
        "    masks = np.array(masks)\n",
        "    segments = np.array(segments)\n",
        "    targets = np.array(targets)\n",
        "\n",
        "    return [tokens, masks, segments], targets"
      ],
      "metadata": {
        "id": "9fViBzMLbHt9"
      },
      "execution_count": 207,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train 데이터를 Bert의 Input 타입에 맞게 변환\n",
        "\n",
        "train_x, train_y = convert_data(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FcB1LWQBbLB8",
        "outputId": "96b660b5-7949-4f57-93ca-61d9ce7d90fa"
      },
      "execution_count": 208,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2017it [00:02, 989.76it/s] \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# test 데이터를 Bert의 Input 타입에 맞게 변환\n",
        "\n",
        "test_x, test_y = convert_data(X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tiaZ-f_RbNXl",
        "outputId": "05121516-6c0c-469e-dcf5-d7cb40ca29fd"
      },
      "execution_count": 209,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "505it [00:00, 1084.51it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. BERT를 활용한 파인튜닝"
      ],
      "metadata": {
        "id": "_8hRf3kebPV5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# token, mask, segment 입력 정의\n",
        "\n",
        "token_inputs = tf.keras.layers.Input((MAX_SEQ_LEN,), dtype = tf.int32, name = 'input_word_ids')\n",
        "mask_inputs = tf.keras.layers.Input((MAX_SEQ_LEN,), dtype = tf.int32, name = 'input_masks')\n",
        "segment_inputs = tf.keras.layers.Input((MAX_SEQ_LEN,), dtype = tf.int32, name = 'input_segment')\n",
        "bert_outputs = model([token_inputs, mask_inputs, segment_inputs])"
      ],
      "metadata": {
        "id": "pzyp62WMbRSA"
      },
      "execution_count": 210,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bert_outputs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qfvOT5M9beZs",
        "outputId": "0d9f4216-48f8-401f-a181-c5d10b1f2a1f"
      },
      "execution_count": 211,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TFSequenceClassifierOutput(loss=None, logits=<KerasTensor: shape=(None, 3) dtype=float32 (created by layer 'tf_bert_for_sequence_classification_3')>, hidden_states=None, attentions=None)"
            ]
          },
          "metadata": {},
          "execution_count": 211
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bert_output = bert_outputs[0]"
      ],
      "metadata": {
        "id": "FxDP34c4bgIb"
      },
      "execution_count": 212,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. 모델 컴파일"
      ],
      "metadata": {
        "id": "PmbMDOC6bhOj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DROPOUT_RATE = 0.5\n",
        "NUM_CLASS = 2\n",
        "dropout = tf.keras.layers.Dropout(DROPOUT_RATE)(bert_output)\n",
        "# Multi-class classification 문제이므로 activation function은 softmax로 설정\n",
        "\n",
        "sentiment_layer = tf.keras.layers.Dense(NUM_CLASS, activation='softmax', kernel_initializer = tf.keras.initializers.TruncatedNormal(stddev=0.02))(dropout)\n",
        "sentiment_model = tf.keras.Model([token_inputs, mask_inputs, segment_inputs], sentiment_layer)"
      ],
      "metadata": {
        "id": "xPWpKpvgbiWl"
      },
      "execution_count": 213,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 옵티마이저 Rectified Adam 하이퍼파리미터 조정\n",
        "OPTIMIZER_NAME = 'RAdam'\n",
        "LEARNING_RATE = 5e-5\n",
        "TOTAL_STEPS = 10000\n",
        "MIN_LR = 1e-5\n",
        "WARMUP_PROPORTION = 0.1\n",
        "EPSILON = 1e-8\n",
        "CLIPNORM = 1.0\n",
        "optimizer = tfa.optimizers.RectifiedAdam(learning_rate = LEARNING_RATE,\n",
        "                                          total_steps = TOTAL_STEPS,\n",
        "                                          warmup_proportion = WARMUP_PROPORTION,\n",
        "                                          min_lr = MIN_LR,\n",
        "                                          epsilon = EPSILON,\n",
        "                                          clipnorm = CLIPNORM)"
      ],
      "metadata": {
        "id": "r87Tv4a1blNA"
      },
      "execution_count": 214,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 감정분류 모델 컴파일\n",
        "sentiment_model.compile(optimizer = optimizer,\n",
        "                        loss = tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "                        metrics = ['accuracy'])"
      ],
      "metadata": {
        "id": "nogdgD8zbnVA"
      },
      "execution_count": 215,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. EarlyStopping 설정"
      ],
      "metadata": {
        "id": "H1FLe0gQbo5M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MIN_DELTA = 1e-3\n",
        "PATIENCE = 5\n",
        "\n",
        "early_stopping = EarlyStopping(\n",
        "    monitor = \"val_accuracy\",\n",
        "    min_delta = MIN_DELTA,\n",
        "    patience = PATIENCE)"
      ],
      "metadata": {
        "id": "OKhBapwUbrIh"
      },
      "execution_count": 216,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. 최고 성능 모델 저장"
      ],
      "metadata": {
        "id": "gq_2xlk6btrr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 최고 성능의 모델 파일을 저장할 이름과 경로 설정\n",
        "BEST_MODEL_NAME = './model/best_model.h5'"
      ],
      "metadata": {
        "id": "at5ZP7m_bvil"
      },
      "execution_count": 217,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_checkpoint = ModelCheckpoint(\n",
        "    filepath = BEST_MODEL_NAME,\n",
        "    monitor = \"val_loss\",\n",
        "    mode = \"min\",\n",
        "    save_best_only = True, # 성능 향상 시에만 모델 저장\n",
        "    verbose = 1\n",
        ")"
      ],
      "metadata": {
        "id": "35RPY_unbxG9"
      },
      "execution_count": 219,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "callbacks = [early_stopping, model_checkpoint]"
      ],
      "metadata": {
        "id": "17BRT10DbyQK"
      },
      "execution_count": 220,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8. 감정 분류 모델 학습"
      ],
      "metadata": {
        "id": "y2wyS8kzbzKx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 10\n",
        "BATCH_SIZE = 32"
      ],
      "metadata": {
        "id": "vOJMkELpb02I"
      },
      "execution_count": 221,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_x), type(train_x[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TwvftRx8WNDb",
        "outputId": "7eb02587-52b5-47c3-bcbe-8a20df6c483e"
      },
      "execution_count": 222,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3, numpy.ndarray)"
            ]
          },
          "metadata": {},
          "execution_count": 222
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentiment_model.fit(train_x, train_y,\n",
        "                    epochs = EPOCHS,\n",
        "                    shuffle = True,\n",
        "                    batch_size = BATCH_SIZE,\n",
        "                    validation_data = (test_x, test_y),\n",
        "                    callbacks = callbacks\n",
        "                    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IyOG1o91b3Jt",
        "outputId": "a0361922-48a0-45bd-8369-770cd1db4a0d"
      },
      "execution_count": 223,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "64/64 [==============================] - ETA: 0s - loss: 0.6927 - accuracy: 0.5240\n",
            "Epoch 1: val_loss improved from inf to 0.69198, saving model to ./model/best_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r64/64 [==============================] - 93s 595ms/step - loss: 0.6927 - accuracy: 0.5240 - val_loss: 0.6920 - val_accuracy: 0.5327\n",
            "Epoch 2/10\n",
            "64/64 [==============================] - ETA: 0s - loss: 0.6907 - accuracy: 0.5736\n",
            "Epoch 2: val_loss improved from 0.69198 to 0.68875, saving model to ./model/best_model.h5\n",
            "64/64 [==============================] - 32s 503ms/step - loss: 0.6907 - accuracy: 0.5736 - val_loss: 0.6887 - val_accuracy: 0.6931\n",
            "Epoch 3/10\n",
            "64/64 [==============================] - ETA: 0s - loss: 0.6851 - accuracy: 0.7080\n",
            "Epoch 3: val_loss improved from 0.68875 to 0.67827, saving model to ./model/best_model.h5\n",
            "64/64 [==============================] - 32s 507ms/step - loss: 0.6851 - accuracy: 0.7080 - val_loss: 0.6783 - val_accuracy: 0.8396\n",
            "Epoch 4/10\n",
            "64/64 [==============================] - ETA: 0s - loss: 0.6659 - accuracy: 0.8037\n",
            "Epoch 4: val_loss improved from 0.67827 to 0.63749, saving model to ./model/best_model.h5\n",
            "64/64 [==============================] - 48s 751ms/step - loss: 0.6659 - accuracy: 0.8037 - val_loss: 0.6375 - val_accuracy: 0.8950\n",
            "Epoch 5/10\n",
            "64/64 [==============================] - ETA: 0s - loss: 0.6172 - accuracy: 0.8314\n",
            "Epoch 5: val_loss improved from 0.63749 to 0.57670, saving model to ./model/best_model.h5\n",
            "64/64 [==============================] - 28s 442ms/step - loss: 0.6172 - accuracy: 0.8314 - val_loss: 0.5767 - val_accuracy: 0.8931\n",
            "Epoch 6/10\n",
            "64/64 [==============================] - ETA: 0s - loss: 0.5610 - accuracy: 0.8597\n",
            "Epoch 6: val_loss improved from 0.57670 to 0.51522, saving model to ./model/best_model.h5\n",
            "64/64 [==============================] - 30s 465ms/step - loss: 0.5610 - accuracy: 0.8597 - val_loss: 0.5152 - val_accuracy: 0.9208\n",
            "Epoch 7/10\n",
            "64/64 [==============================] - ETA: 0s - loss: 0.5031 - accuracy: 0.8860\n",
            "Epoch 7: val_loss improved from 0.51522 to 0.46682, saving model to ./model/best_model.h5\n",
            "64/64 [==============================] - 48s 754ms/step - loss: 0.5031 - accuracy: 0.8860 - val_loss: 0.4668 - val_accuracy: 0.9188\n",
            "Epoch 8/10\n",
            "64/64 [==============================] - ETA: 0s - loss: 0.4632 - accuracy: 0.8795\n",
            "Epoch 8: val_loss improved from 0.46682 to 0.42867, saving model to ./model/best_model.h5\n",
            "64/64 [==============================] - 39s 609ms/step - loss: 0.4632 - accuracy: 0.8795 - val_loss: 0.4287 - val_accuracy: 0.9208\n",
            "Epoch 9/10\n",
            "64/64 [==============================] - ETA: 0s - loss: 0.4309 - accuracy: 0.8830\n",
            "Epoch 9: val_loss improved from 0.42867 to 0.38557, saving model to ./model/best_model.h5\n",
            "64/64 [==============================] - 29s 454ms/step - loss: 0.4309 - accuracy: 0.8830 - val_loss: 0.3856 - val_accuracy: 0.9347\n",
            "Epoch 10/10\n",
            "64/64 [==============================] - ETA: 0s - loss: 0.3794 - accuracy: 0.9063\n",
            "Epoch 10: val_loss improved from 0.38557 to 0.36391, saving model to ./model/best_model.h5\n",
            "64/64 [==============================] - 39s 613ms/step - loss: 0.3794 - accuracy: 0.9063 - val_loss: 0.3639 - val_accuracy: 0.9248\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7bdffb9abbb0>"
            ]
          },
          "metadata": {},
          "execution_count": 223
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 9. 감정 분류의 예측값 계산"
      ],
      "metadata": {
        "id": "KJIgYrUScHea"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 최고 성능의 모델 불러오기\n",
        "sentiment_model_best = tf.keras.models.load_model(BEST_MODEL_NAME,\n",
        "                                                  custom_objects={'TFBertForSequenceClassification': TFBertForSequenceClassification})"
      ],
      "metadata": {
        "id": "bKEZRLkab3ob"
      },
      "execution_count": 340,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_data2(X_data):\n",
        "    # BERT 입력으로 들어가는 token, mask, segment, target 저장용 리스트\n",
        "    tokens, masks, segments = [], [], []\n",
        "\n",
        "    for X in tqdm(X_data):\n",
        "        X = '[CLS] ' + str(X) + ' [SEP]'\n",
        "        # token: 입력 문장 토큰화\n",
        "        token = tokenizer.encode(X, truncation = True, padding = 'max_length', max_length = MAX_SEQ_LEN)\n",
        "\n",
        "        # Mask: 토큰화한 문장 내 패딩이 아닌 경우 1, 패딩인 경우 0으로 초기화\n",
        "        num_zeros = token.count(0)\n",
        "        mask = [1] * (MAX_SEQ_LEN - num_zeros) + [0] * num_zeros\n",
        "\n",
        "        # segment: 문장 전후관계 구분: 오직 한 문장이므로 모두 0으로 초기화\n",
        "        segment = [0]*MAX_SEQ_LEN\n",
        "\n",
        "        tokens.append(token)\n",
        "        masks.append(mask)\n",
        "        segments.append(segment)\n",
        "\n",
        "    # numpy array로 저장\n",
        "    tokens = np.array(tokens)\n",
        "    masks = np.array(masks)\n",
        "    segments = np.array(segments)\n",
        "\n",
        "    return [tokens, masks, segments]"
      ],
      "metadata": {
        "id": "kgXlEcj_um3p"
      },
      "execution_count": 341,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 10. 파이프라이닝"
      ],
      "metadata": {
        "id": "F8g3k5s96DQe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import FunctionTransformer\n",
        "\n",
        "pipe = Pipeline([('preprocess', FunctionTransformer(convert_data2)),\n",
        "                 ('model', sentiment_model_best)])"
      ],
      "metadata": {
        "id": "AulXkYLeZfho"
      },
      "execution_count": 342,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sent = [\"야, 이 씨발 새끼야, 개새끼야, 좆같은 새끼야, 너 때문에 분위기가 이렇게 좆같이 된 거야 사랑해 쪽쪽 강아지 엘지 너무 좋아\", \"우리집 강아지 너무 귀여워 사랑해 밥 많이 먹어\", \"배고파\"]\n",
        "pipe.predict(sent)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jZoiACgjo-60",
        "outputId": "c72c2118-7dc2-4004-924b-d2ac776e3cf8"
      },
      "execution_count": 343,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3/3 [00:00<00:00, 1961.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 3s 3s/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.2420646 , 0.7579354 ],\n",
              "       [0.75851274, 0.24148725],\n",
              "       [0.7566653 , 0.2433347 ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 343
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 11. LIME"
      ],
      "metadata": {
        "id": "tcotC6qeEMVm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install lime"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b6A0mLn_-onS",
        "outputId": "98e2c742-bb24-44d7-ac3f-713ca14ef75e"
      },
      "execution_count": 344,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: lime in /usr/local/lib/python3.10/dist-packages (0.2.0.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from lime) (3.7.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from lime) (1.23.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from lime) (1.11.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from lime) (4.66.1)\n",
            "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.10/dist-packages (from lime) (1.2.2)\n",
            "Requirement already satisfied: scikit-image>=0.12 in /usr/local/lib/python3.10/dist-packages (from lime) (0.19.3)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.12->lime) (3.2)\n",
            "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.12->lime) (9.4.0)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.12->lime) (2.31.6)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.12->lime) (2023.9.26)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.12->lime) (1.4.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.12->lime) (23.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.18->lime) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.18->lime) (3.2.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lime) (1.1.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lime) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lime) (4.43.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lime) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lime) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lime) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->lime) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from lime.lime_text import LimeTextExplainer\n",
        "\n",
        "explainer = LimeTextExplainer(class_names=[0, 1])"
      ],
      "metadata": {
        "id": "ps82M36nEfii"
      },
      "execution_count": 345,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipe.predict([sent[0]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mx4d0sBDnbzm",
        "outputId": "db910565-ffce-4b8a-f78d-435a03919647"
      },
      "execution_count": 346,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 1297.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 77ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.2420646, 0.7579354]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 346
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "exp = explainer.explain_instance(sent[0], pipe.predict, top_labels=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5QMPXA6FVbMR",
        "outputId": "564e9c91-779c-4640-e20d-4920b250b38a"
      },
      "execution_count": 347,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5000/5000 [00:01<00:00, 2829.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "157/157 [==============================] - 21s 131ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "exp.available_labels()[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5EtlxxKScj7T",
        "outputId": "bda09285-bd5e-4391-b41b-fb91bfa4b30b"
      },
      "execution_count": 348,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 348
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "temp = exp.as_list(label=exp.available_labels()[0])"
      ],
      "metadata": {
        "id": "RclZJltGdQvT"
      },
      "execution_count": 349,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temp2 = np.array([[x[0], x[1]] for x in temp])\n",
        "temp3 = temp2.T\n",
        "temp3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6SIpQMzldh5Z",
        "outputId": "ab744603-aa62-45d6-826c-b95196c9ec50"
      },
      "execution_count": 350,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([['개새끼야', '새끼야', '씨발', '사랑해', '너무', '너', '강아지', '좋아', '분위기가', '거야'],\n",
              "       ['0.30429028921363177', '0.1937487470789795',\n",
              "        '0.18560275543508428', '-0.07659260415906342',\n",
              "        '-0.0646635506252211', '0.061493085650806356',\n",
              "        '-0.048169215880460324', '-0.04806852268828535',\n",
              "        '-0.04518054335651558', '0.03656291012099749']], dtype='<U32')"
            ]
          },
          "metadata": {},
          "execution_count": 350
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "exp.show_in_notebook()"
      ],
      "metadata": {
        "id": "0II4KFH8heCD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}